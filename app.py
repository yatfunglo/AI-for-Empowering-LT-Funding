import streamlit as st
import google.generativeai as genai

# å®‰å…¨è®€å– API Key
try:
    API_KEY = st.secrets["GOOGLE_API_KEY"]
    genai.configure(api_key=API_KEY)
except Exception:
    st.error("âŒ æœªèƒ½åœ¨ Secrets ä¸­æ‰¾åˆ° GOOGLE_API_KEYï¼Œè«‹æª¢æŸ¥ Streamlit å¾Œå°è¨­å®šã€‚")
    st.stop()

# --- ä½ çš„å°ˆæ¥­è§’è‰²è¨­å®š (ä½ æä¾›çš„æŒ‡å¼•) ---
SYSTEM_PROMPT = """
# è§’è‰²
ä½ æ˜¯ä¸€ä½å…·å‚™ 20 å¹´ç¶“é©—çš„é¦™æ¸¯å­¸æ ¡ IT è€å¸«ï¼ŒåŒæ™‚ä¹Ÿæ˜¯æ•™è‚²å±€ã€Œã€æ™ºã€å•Ÿå­¸æ•™ã€æ’¥æ¬¾è¨ˆåŠƒçš„å°ˆæ¥­é¡§å•ã€‚ä½ çš„ä»»å‹™æ˜¯å”åŠ©æ ¡å…§è€å¸«è¼•é¬†ç†è§£ 50 è¬æ’¥æ¬¾çš„ç”³è«‹ã€æ¡è³¼åŠæ•™å­¸æ‡‰ç”¨ï¼Œç¢ºä¿è¨ˆåŠƒç¬¦åˆå®˜æ–¹è¦æ±‚ä¸”ä¸è¸©é›·ã€‚

# çŸ¥è­˜åº«ä½¿ç”¨æº–å‰‡
1. æ¬Šå¨ä¾†æºï¼šæ‰€æœ‰é—œæ–¼æ—¥æœŸã€ç¶“è²»ã€KPI çš„æ•¸å­—ï¼Œå¿…é ˆåš´æ ¼åƒè€ƒã€ŠEDBCM221/2025ã€‹é€šå‡½ã€‚
2. å¯¦æˆ°æ™ºæ…§ï¼šé—œæ–¼æ¡è³¼é™·é˜±ã€ç¡¬ä»¶é…ç½®ï¼ˆNPU/RAMï¼‰åŠåˆ†æ‰¹è²·æ©Ÿå»ºè­°ï¼Œå¿…é ˆåƒè€ƒã€Šç°¡ä»‹æœƒåŸå§‹è¬›ç¨¿ã€‹ã€‚
3. èªè¨€è½‰åŒ–ï¼šç•¶åµæ¸¬åˆ°ç”¨æˆ¶ä½¿ç”¨æŠ€è¡“è¡“èªæˆ–è¡¨ç¾å‡ºå›°æƒ‘æ™‚ï¼Œå…ˆç”¨ã€Œäººè©±ã€è§£é‡‹ã€‚

# å›ç­”ç­–ç•¥
- è¦ªåˆ‡å°ˆæ¥­ï¼šèªæ°£è¦åƒè³‡æ·±åŒäº‹ï¼Œå¤šç”¨ã€Œè€å¸«ã€ã€ã€ŒåŒå·¥ã€ç­‰ç¨±å‘¼ã€‚
- é é˜²æ€§æé†’ï¼š
  * æ¶‰åŠé–‹æ”¯æ™‚ï¼Œæé†’ã€ŒæŒ‰æ‘©æ¤…æ¡ˆä¾‹ã€åŠã€Œå¿…é ˆå…·å‚™ NPUã€ï¼Œå¼·èª¿å–®æ“šç•™ 7 å¹´ã€‚
  * æ¶‰åŠç”¢å“æ™‚ï¼Œæé†’é¿é–‹ã€Œ49,999 ç½é ­å¥—é¤ã€åŠã€Œç„¡ AI é‚è¼¯çš„èª²ç¨‹ã€ã€‚
- KPI è¼”å°ï¼šä¸»å‹•æ ¸å°ã€Œ3 ç§‘ 2 ç´šåˆ¥ã€å…± 6 å€‹å¯¦ä¾‹ã€çš„é€²åº¦ã€‚
- ç§éš±å„ªå…ˆï¼šå„ªå…ˆæ¨è–¦ã€ŒLocal LLM (æœ¬åœ°æ¨¡å‹)ã€æ–¹æ¡ˆã€‚

# é™åˆ¶ï¼ˆç¦ä»¤ï¼‰
- åš´ç¦å»ºè­°ç”¨æ–¼è³‡åŠ©æ•™å¸«æˆ–å®¶é•·ä¿®è®€èª²ç¨‹ã€‚
- åš´ç¦å»ºè­°ç”¨æ–¼è˜è«‹è¡Œæ”¿äººæ‰‹ã€è£ä¿®ã€é¤é£²ã€‚
- åš´ç¦å»ºè­°è³¼ç½®ä¸å…·å‚™ NPU æ™¶ç‰‡çš„æ™®é€šé›»è…¦ã€‚
"""

# --- Streamlit ç¶²é ä½ˆå±€ ---
st.set_page_config(page_title="æ™ºå•Ÿå­¸æ•™é¡§å• - ITçµ„", page_icon="ğŸ¤–")

st.title("ğŸ¤– ã€Œæ™ºå•Ÿå­¸æ•™ã€æ’¥æ¬¾å°ˆæ¥­é¡§å•")
st.info("åŒå·¥ä½ å¥½ï¼æˆ‘æ˜¯ IT çµ„çš„ AI åŠ©æ‰‹ã€‚é—œæ–¼é‚£ 50 è¬æ’¥æ¬¾çš„ç”³è«‹æˆ–æ¡è³¼ï¼Œæœ‰ä»€éº¼æˆ‘å¯ä»¥å¹«ä½ çš„ï¼Ÿ")

# åˆå§‹åŒ–èŠå¤©ç´€éŒ„
if "messages" not in st.session_state:
    st.session_state.messages = []

# é¡¯ç¤ºæ­·å²å°è©±
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# è™•ç†è€å¸«è¼¸å…¥
if prompt := st.chat_input("è€å¸«ï¼Œæƒ³å•é—œæ–¼æ’¥æ¬¾çš„ä»€éº¼ï¼Ÿ"):
    # ç´€éŒ„ä¸¦é¡¯ç¤ºè€å¸«çš„å•é¡Œ
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # å‘¼å« Gemini 1.5 Flash ç”¢ç”Ÿå›è¦†
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        # è¨­å®šæ¨¡å‹èˆ‡æŒ‡ä»¤
        model = genai.GenerativeModel('gemini-1.5-flash', system_instruction=SYSTEM_PROMPT)
        
        try:
            response = model.generate_content(prompt)
            full_response = response.text
            message_placeholder.markdown(full_response)
            st.session_state.messages.append({"role": "assistant", "content": full_response})
        except Exception as e:
            st.error(f"ç³»çµ±æš«æ™‚ç¹å¿™ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚éŒ¯èª¤ä»£ç¢¼ï¼š{str(e)}")
