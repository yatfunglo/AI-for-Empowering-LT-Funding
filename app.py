import streamlit as st
from google import genai

# 1. åˆå§‹åŒ–æ–°ç‰ˆ Client
try:
    # ç¢ºä¿ä½ å·²åœ¨ Streamlit Secrets å¡«å¯« GOOGLE_API_KEY
    API_KEY = st.secrets["GOOGLE_API_KEY"]
    client = genai.Client(api_key=API_KEY)
except Exception:
    st.error("âŒ æœªèƒ½åœ¨ Secrets ä¸­æ‰¾åˆ° GOOGLE_API_KEYï¼Œè«‹æª¢æŸ¥è¨­å®šã€‚")
    st.stop()

# 2. ä½ çš„å°ˆæ¥­è§’è‰²èˆ‡æŒ‡å¼•
SYSTEM_PROMPT = """
# è§’è‰²
ä½ æ˜¯ä¸€ä½å…·å‚™ 20 å¹´ç¶“é©—çš„é¦™æ¸¯å­¸æ ¡ IT è€å¸«ï¼ŒåŒæ™‚ä¹Ÿæ˜¯æ•™è‚²å±€ã€Œã€æ™ºã€å•Ÿå­¸æ•™ã€æ’¥æ¬¾è¨ˆåŠƒçš„å°ˆæ¥­é¡§å•ã€‚ä½ çš„ä»»å‹™æ˜¯å”åŠ©æ ¡å…§è€å¸«è¼•é¬†ç†è§£ 50 è¬æ’¥æ¬¾çš„ç”³è«‹ã€æ¡è³¼åŠæ•™å­¸æ‡‰ç”¨ï¼Œç¢ºä¿è¨ˆåŠƒç¬¦åˆå®˜æ–¹è¦æ±‚ä¸”ä¸è¸©é›·ã€‚

# çŸ¥è­˜åº«ä½¿ç”¨æº–å‰‡
- æ¬Šå¨ä¾†æºï¼šæ‰€æœ‰æ•¸å­—ï¼ˆ50è¬ä¸Šé™ã€3ç§‘2ç´šåˆ¥å…±6å¯¦ä¾‹ï¼‰åš´æ ¼åƒè€ƒã€ŠEDBCM221/2025ã€‹é€šå‡½ã€‚
- å¯¦æˆ°æ™ºæ…§ï¼šé—œæ–¼ç¡¬ä»¶é…ç½®ï¼ˆNPU/RAMï¼‰åƒè€ƒã€Šç°¡ä»‹æœƒåŸå§‹è¬›ç¨¿ã€‹ã€‚
- èªè¨€è½‰åŒ–ï¼šä½¿ç”¨ã€ŠæŠ€è¡“èˆ‡è¡Œæ”¿åè©äººè©±æ‰‹å†Šã€‹ï¼Œå°‡è¡“èªè½‰ç‚ºã€Œäººè©±ã€ã€‚

# å›ç­”ç­–ç•¥
- è¦ªåˆ‡å°ˆæ¥­ï¼šèªæ°£åƒè³‡æ·±åŒäº‹ï¼Œç¨±å‘¼ç”¨æˆ¶ç‚ºã€Œè€å¸«ã€æˆ–ã€ŒåŒå·¥ã€ã€‚
- é é˜²æ€§æé†’ï¼šæã€ŒæŒ‰æ‘©æ¤…æ¡ˆä¾‹ã€ã€ã€Œå¿…é ˆå…·å‚™ NPUã€ã€ã€Œå–®æ“šç•™ 7 å¹´ã€ã€ã€Œé¿é–‹ 49,999 ç½é ­å¥—é¤ã€ã€‚
- ç§éš±å„ªå…ˆï¼šå„ªå…ˆæ¨è–¦ã€ŒLocal LLM (æœ¬åœ°æ¨¡å‹)ã€æ–¹æ¡ˆã€‚

# é™åˆ¶ï¼ˆç¦ä»¤ï¼‰
- åš´ç¦å»ºè­°ç”¨æ–¼ï¼šè³‡åŠ©æ•™å¸«/å®¶é•·èª²ç¨‹ã€è˜è«‹è¡Œæ”¿äººæ‰‹ã€è£ä¿®ã€é¤é£²ã€‚
- åš´ç¦è³¼ç½®ä¸å…·å‚™ NPU æ™¶ç‰‡çš„æ™®é€šé›»è…¦ã€‚
"""

# --- ç¶²é ä»‹é¢ ---
st.set_page_config(page_title="æ™ºå•Ÿå­¸æ•™å°ˆæ¥­é¡§å•", page_icon="ğŸ¤–")
st.title("ğŸ¤– ã€Œæ™ºå•Ÿå­¸æ•™ã€æ’¥æ¬¾å°ˆæ¥­é¡§å•")
st.info("åŒå·¥ä½ å¥½ï¼æˆ‘æ˜¯ IT çµ„çš„ AI åŠ©æ‰‹ã€‚é—œæ–¼é‚£ 50 è¬æ’¥æ¬¾ï¼Œæœ‰ä»€éº¼æˆ‘å¯ä»¥å¹«ä½ çš„ï¼Ÿ")

if "messages" not in st.session_state:
    st.session_state.messages = []

# é¡¯ç¤ºå°è©±æ­·å²
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# è™•ç†ç”¨æˆ¶è¼¸å…¥
if prompt := st.chat_input("è€å¸«ï¼Œæœ‰å’©å¯ä»¥å¹«åˆ°ä½ ï¼Ÿ"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        
        try:
            # ğŸ’¡ æ ¸å¿ƒä¿®æ­£ 1ï¼šæ˜ç¢ºæŒ‡å®š tools æ ¼å¼
            # ğŸ’¡ æ ¸å¿ƒä¿®æ­£ 2ï¼šç¢ºä¿ model åç¨±ç‚º 'gemini-1.5-flash'
            response = client.models.generate_content(
                model='gemini-1.5-flash', 
                contents=prompt,
                config={
                    'system_instruction': SYSTEM_PROMPT,
                    'tools': [{'google_search': {}}] 
                }
            )
            
            full_response = response.text
            message_placeholder.markdown(full_response)
            st.session_state.messages.append({"role": "assistant", "content": full_response})
            
        except Exception as e:
            # å‚™ç”¨æ–¹æ¡ˆï¼šå¦‚æœ Google Search å°è‡´ 404ï¼Œå˜—è©¦ç´”æ–‡å­—æ¨¡å¼
            try:
                response = client.models.generate_content(
                    model='gemini-1.5-flash',
                    contents=prompt,
                    config={'system_instruction': SYSTEM_PROMPT}
                )
                message_placeholder.markdown(response.text)
                st.session_state.messages.append({"role": "assistant", "content": response.text})
            except Exception as e2:
                st.error("âš ï¸ ç³»çµ±é€£æ¥å¾®èª¿ä¸­ï¼Œè«‹è€å¸«é‡è©¦ä¸€æ¬¡ã€‚")
                st.caption(f"æŠ€è¡“æ—¥èªŒ: {str(e2)}")
